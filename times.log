numPy:
Training inputs: [[0 0 1]
 [1 1 1]
 [1 0 1]
 [0 1 1]]
Training outputs: [[0]
 [1]
 [1]
 [0]]
Random starting synaptic weights: [[ 0.53370987]
 [-0.11020444]
 [ 0.41430282]]
Synaptic weights after training: [[10.38039359]
 [-0.20679779]
 [-4.98428352]]
Outputs after training [[0.00679832]
 [0.99445494]
 [0.99548617]
 [0.00553532]]
Output for novel input: [ 1,0,0 ] =>  [0.99996897]
real 0.27
user 0.26
sys 0.00

GHC:
Training inputs:
[[0.0,0.0,1.0],[1.0,1.0,1.0],[1.0,0.0,1.0],[0.0,1.0,1.0]]

Training outputs:
[[0.0],[1.0],[1.0],[0.0]]

Random starting synaptic weights:
[[-0.6127751],[-0.47651553],[-0.5089884]]

Weights after training: [[10.38022],[-0.20675038],[-4.984234]]

Output  after training: [[6.7986585e-3],[0.99445456],[0.9954856],[5.535852e-3]]

New Input and Output with trained weights:[[1.0,0.0,0.0]]=>[[0.999969]]
real 0.21
user 0.19
sys 0.02

Racket:

Training inputs:
#<array #(4 3) #[0 0 1 1 1 1 1 0 1 0 1 1]>

Training outputs:
#<array #(4 1) #[0 1 1 0]>

Random starting synaptic weights:
#<array #(3 1) #[0.6242961361663408 -0.4201957428363884 -0.7461329706003093]>

Synaptic weights after training:
#<array #(3 1) #[10.380513802594248 -0.20670208381502125 -4.984400756264873]>

Outputs after training:
#<array #(4 1) #[0.006797529869617193 0.994455481296192 0.9954861811706819 0.005535197625391331]>

Output for novel input: [1 0 0 ] => 
#<array #(1 1) #[0.9999689696510321]>
real 10.12
user 9.96
sys 0.16

Typed Racket:

Training inputs:
#<array #(4 3) #[0.0 0.0 1.0 1.0 1.0 1.0 1.0 0.0 1.0 0.0 1.0 1.0]>

Training outputs:
#<array #(4 1) #[0 1 1 0]>

Random starting synaptic weights:
#<array #(3 1) #[0.07228536415737041 0.8762874282588684 -0.4663532103880932]>

Synaptic weights after training:
#<array #(3 1) #[0.07228536415737041 0.8762874282588684 -0.4663532103880932]>

Outputs after training:
#<array #(4 1) #[0.00679665639021473 0.994455864907664 0.995485098594295 0.005536194497695936]>

Output for novel input: [1 0 0 ] => 
#<array #(1 1) #[0.9999689646126503]>
real 2.34
user 2.00
sys 0.34

Octave:
training_inputs =

   0   0   1
   1   1   1
   1   0   1
   0   1   1

training_outputs =

   0
   1
   1
   0

synaptic_weights =

  -0.958260
   0.129426
  -0.096646

--
After training...
synaptic_weights =

   10.38015
   -0.20666
   -4.98424

output =

   0.0067986
   0.9944546
   0.9954853
   0.0055363

Output for novel input: [1 0 0 ] =>  0.99997
real 0.55
user 0.53
sys 0.02

Julia:
Training inputs
4Ã—3 Array{Int64,2}:
 0  0  1
 1  1  1
 1  0  1
 0  1  1
Training Outputs
4-element Array{Int64,1}:
 0
 1
 1
 0
Initial random weights
3-element Array{Float64,1}:
  0.04645823443736896
 -0.8491742727624167 
 -0.34053619774638433
--

Weights after training: 
3-element Array{Float64,1}:
 14.815916375845541  
 -0.37594281349440717
 -9.506354592431443  

Outputs after training
4-element Array{Float64,1}:
 7.437588109029032e-5
 0.9928508979405708  
 0.9950801076401096  
 5.107076203689921e-5

Outputs for novel(untrained) case
[0.9999996322699558]
real 1.55
user 1.47
sys 0.06

Node.js:
training inputs: [ [ 0, 0, 1 ], [ 1, 1, 1 ], [ 1, 0, 1 ], [ 0, 1, 1 ] ]
training outputs [ [ 0 ], [ 1 ], [ 1 ], [ 0 ] ]
[
  [ 0.9163833217963999 ],
  [ -0.7730735786179288 ],
  [ 0.9940901566546603 ]
]
Percetpron out:  [
  [ 0.006799380391673016 ],
  [ 0.9944544546945895 ],
  [ 0.9954873917902747 ],
  [ 0.005534198275792887 ]
]

Final weights:  [
  [ 10.38050919745027 ],
  [ -0.20715768791251313 ],
  [ -4.9841267091359045 ]
]
Output from novel input [1 0 0 ] =>  [ [ 0.9999689695081371 ] ]
real 0.70
user 1.01
sys 0.04

